{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c5d71e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T15:58:06.662006Z",
     "start_time": "2024-04-02T15:58:05.515153Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "import random, pickle \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "# from autosklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import autosklearn\n",
    "from autosklearn.regression import AutoSklearnRegressor\n",
    "from autosklearn.classification import AutoSklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc4f3a4-3a62-4b00-a3db-6d0961229eba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T15:58:07.378654Z",
     "start_time": "2024-04-02T15:58:07.354937Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data_latest_average_non_zero_raw_secondary_task_repeated_insole.pkl\")\n",
    "\n",
    "# # if we decided to remove duplicates in participant samples\n",
    "# duplicate_rows = df.duplicated(subset=['participant_number','left_or_right'], keep='first')\n",
    "# df = df[~duplicate_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d8cd08-7847-489c-8126-46027261920e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T15:58:08.333288Z",
     "start_time": "2024-04-02T15:58:08.314972Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fca48d-ffdd-459c-b45b-56c852c31639",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T15:57:00.320940Z",
     "start_time": "2024-04-02T15:57:00.293029Z"
    }
   },
   "outputs": [],
   "source": [
    "participant_list = df.participant_number.drop_duplicates().to_list()\n",
    "random.Random(420).shuffle(participant_list)\n",
    "print(participant_list)\n",
    "\n",
    "participant_list_train, participant_list_test = train_test_split(participant_list, random_state=115,  train_size=0.85)\n",
    "\n",
    "print(participant_list_train, participant_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7014a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=3)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "df_test = df[df['participant_number'].isin(participant_list_test)] #select test participants\n",
    "df_test = df_test.sample(frac=1).reset_index(drop=True) #shuffle and reset_index\n",
    "# df_test.reset_index(inplace=True,drop=True)\n",
    "df_train = df[df['participant_number'].isin(participant_list_train)] #select train participants\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True) #shuffle and reset_index\n",
    "# df_train.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c21324",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f9fe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns.tolist()[1:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a30f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for feature_num, feature_name in enumerate(df_test.columns.tolist()[1:17]):\n",
    "\n",
    "\n",
    "    print(\"Current Feature Classifier:\", feature_name)\n",
    "\n",
    "    y_train = df_train[[feature_name]].values\n",
    "    x_train = np.asarray(df_train.input_features.tolist())\n",
    "\n",
    "\n",
    "    y_test = df_test[[feature_name]].values\n",
    "\n",
    "    x_test = np.asarray(df_test.input_features.tolist())\n",
    "\n",
    "    \n",
    "\n",
    "    # y_train = y_train[:,feature_num]\n",
    "    # y_test  = y_test[:,feature_num]\n",
    "\n",
    "    print(x_train.shape, y_train.shape , x_test.shape, y_test.shape)\n",
    "\n",
    "    automl = AutoSklearnClassifier(\n",
    "        time_left_for_this_task=3600,\n",
    "        per_run_time_limit=180,\n",
    "        memory_limit = 500000,\n",
    "        seed = 14141,\n",
    "        # metric = autosklearn.metrics.balanced_accuracy,\n",
    "        \n",
    "        # resampling_strategy = 'cv'\n",
    "        # resampling_strategy_arguments = {\n",
    "        # \"shuffle\": True,        # Whether to shuffle before splitting data\n",
    "        # # \"folds\": 3              # Used in 'cv' based resampling strategies\n",
    "        # }\n",
    "    )\n",
    "    automl.fit(x_train, y_train)\n",
    "\n",
    "    # save model\n",
    "    with open('data_averaged_time5hours_perRun300_secondary_task_'+ feature_name +'model.pkl', 'wb') as f:\n",
    "        pickle.dump(automl, f)\n",
    "\n",
    "    print(automl.leaderboard())\n",
    "\n",
    "    pprint(automl.show_models(), indent=4)\n",
    "\n",
    "\n",
    "    predictions = automl.predict(x_test)\n",
    "    print(\"Accuracy score:\", accuracy_score(y_test, predictions))\n",
    "\n",
    "    df_test['predictions_' + feature_name] = predictions\n",
    "    df_test['y_test_' + feature_name] = y_test\n",
    "\n",
    "df_test.to_pickle(\"data_averaged_time5hours_perRun300_secondary_task_single_classifiers.pkl\")\n",
    "df_test.to_csv(\"data_averaged_time5hours_perRun300_secondary_task_single_classifiers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9aaf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for feature_num, feature_name in enumerate(df_test.columns.tolist()[6:17]):\n",
    "\n",
    "\n",
    "#     print(\"Current Feature Classifier:\", feature_name)\n",
    "\n",
    "#     y_train = df_train[[feature_name]].values\n",
    "#     x_train = np.asarray(df_train.input_features.tolist())\n",
    "\n",
    "\n",
    "#     y_test = df_test[[feature_name]].values\n",
    "\n",
    "#     x_test = np.asarray(df_test.input_features.tolist())\n",
    "\n",
    "    \n",
    "\n",
    "#     # y_train = y_train[:,feature_num]\n",
    "#     # y_test  = y_test[:,feature_num]\n",
    "\n",
    "#     print(x_train.shape, y_train.shape , x_test.shape, y_test.shape)\n",
    "\n",
    "#     automl = AutoSklearnClassifier(\n",
    "#         time_left_for_this_task=3600,\n",
    "#         per_run_time_limit=180,\n",
    "#         memory_limit = 500000,\n",
    "#         seed = 14141,\n",
    "#         # metric = autosklearn.metrics.balanced_accuracy,\n",
    "        \n",
    "#         # resampling_strategy = 'cv'\n",
    "#         # resampling_strategy_arguments = {\n",
    "#         # \"shuffle\": True,        # Whether to shuffle before splitting data\n",
    "#         # # \"folds\": 3              # Used in 'cv' based resampling strategies\n",
    "#         # }\n",
    "#     )\n",
    "#     automl.fit(x_train, y_train)\n",
    "\n",
    "#     # save model\n",
    "#     with open('data_averaged_time5hours_perRun300_secondary_task_'+ feature_name +'model.pkl', 'wb') as f:\n",
    "#         pickle.dump(automl, f)\n",
    "\n",
    "#     print(automl.leaderboard())\n",
    "\n",
    "#     pprint(automl.show_models(), indent=4)\n",
    "\n",
    "\n",
    "#     predictions = automl.predict(x_test)\n",
    "#     print(\"Accuracy score:\", accuracy_score(y_test, predictions))\n",
    "\n",
    "#     df_test['predictions_' + feature_name] = predictions\n",
    "#     df_test['y_test_' + feature_name] = y_test\n",
    "\n",
    "# df_test.to_pickle(\"data_averaged_time5hours_perRun300_secondary_task_single_classifiers.pkl\")\n",
    "# df_test.to_csv(\"data_averaged_time5hours_perRun300_secondary_task_single_classifiers.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
